{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac192915",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uproot\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, auc, accuracy_score\n",
    "import tensorflow.keras.backend as K\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models, Model\n",
    "import h5py\n",
    "\n",
    "from utils import *\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c7e777",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('HHbbbb.h5', 'r') as f:\n",
    "    X_HHbbbb_isHS = tf.cast(f['HS'][:20000], tf.float32)\n",
    "    X_HHbbbb_isPU = tf.cast(f['PU'][:20000], tf.float32)\n",
    "\n",
    "with h5py.File('PJZ0.h5', 'r') as f:\n",
    "    X_PJZ0 = tf.cast(f['data'][:20000], tf.float32)\n",
    "\n",
    "print(X_HHbbbb_isHS.shape)\n",
    "print(X_HHbbbb_isPU.shape)\n",
    "print(X_PJZ0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9428917",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_layers(event_idx=1, X=X_HHbbbb_isHS+X_HHbbbb_isPU, label='[HHbbbb, PU=200]')\n",
    "plot_layers(event_idx=1, X=X_HHbbbb_isHS, label='[HHbbbb, PU=0]')\n",
    "plot_layers(event_idx=2, X=X_PJZ0, label='[QCD dijet, PU=200]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd6f359",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_pu = 100\n",
    "x_augmented = augment_pu(image=X_HHbbbb_isPU[0], target_pu=target_pu, shift_phi=True)\n",
    "\n",
    "plot_layers(event_idx=None, X=X_HHbbbb_isPU[0], label='[Pure PU, 200]')\n",
    "plot_layers(event_idx=None, X=x_augmented, label=f'[Pure PU, aug. {target_pu}]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a837c52",
   "metadata": {},
   "source": [
    "## build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1546016c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_encoder(input_shape=(64, 50, 6), embedding_dim=128):\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    x = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    x = tf.keras.layers.MaxPooling2D((2, 2))(x)\n",
    "    x = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = tf.keras.layers.MaxPooling2D((2, 2))(x)\n",
    "    x = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "    x = tf.keras.layers.Dense(embedding_dim)(x)\n",
    "    outputs = tf.keras.layers.LayerNormalization()(x)\n",
    "\n",
    "    return tf.keras.Model(inputs, outputs, name=\"encoder\")\n",
    "\n",
    "\n",
    "def build_projection_head(embedding_dim=128, projection_dim=64):\n",
    "    inputs = tf.keras.Input(shape=(embedding_dim,))\n",
    "    x = tf.keras.layers.Dense(embedding_dim, activation='relu')(inputs)\n",
    "    outputs = tf.keras.layers.Dense(projection_dim)(x)\n",
    "\n",
    "    return tf.keras.Model(inputs, outputs, name=\"projection_head\")\n",
    "\n",
    "\n",
    "def vicreg_loss(z1, z2, c_inv=25, c_var=25, c_cov=1, eps=1e-4):\n",
    "    # invariance between positive views\n",
    "    loss_inv = tf.reduce_mean(tf.square(z1 - z2))\n",
    "\n",
    "    # maximize variance per feature dim across sample batch (avoid collapse--learning constant vector)\n",
    "    std_z1 = tf.sqrt(tf.math.reduce_variance(z1, axis=0) + eps)\n",
    "    std_z2 = tf.sqrt(tf.math.reduce_variance(z2, axis=0) + eps)\n",
    "    loss_var = tf.reduce_mean(tf.nn.relu(1 - std_z1)) + tf.reduce_mean(tf.nn.relu(1 - std_z2))\n",
    "\n",
    "    # minimize covariance between feature dims (to reduce learning feature redundancy)\n",
    "    z1_centered = z1 - tf.reduce_mean(z1, axis=0)\n",
    "    z2_centered = z2 - tf.reduce_mean(z2, axis=0)\n",
    "    batch_size = tf.cast(tf.shape(z1)[0], tf.float32)\n",
    "    # covariance matrices for z1 z2\n",
    "    cov_z1 = tf.matmul(tf.transpose(z1_centered), z1_centered) / (batch_size - 1)\n",
    "    cov_z2 = tf.matmul(tf.transpose(z2_centered), z2_centered) / (batch_size - 1)\n",
    "    # get diagonal parts\n",
    "    diag_z1 = tf.linalg.diag(tf.linalg.diag_part(cov_z1))\n",
    "    diag_z2 = tf.linalg.diag(tf.linalg.diag_part(cov_z2))\n",
    "    # subtract diagonal parts from cov matrices to get off-diagonal parts (cov between features)\n",
    "    loss_cov_z1 = tf.reduce_sum(tf.square(cov_z1 - diag_z1)) / tf.cast(tf.shape(z1)[1], tf.float32)\n",
    "    loss_cov_z2 = tf.reduce_sum(tf.square(cov_z2 - diag_z2)) / tf.cast(tf.shape(z2)[1], tf.float32)\n",
    "    loss_cov = loss_cov_z1 + loss_cov_z2\n",
    "\n",
    "    loss = c_inv * loss_inv + c_var * loss_var + c_cov * loss_cov\n",
    "\n",
    "    return loss, loss_inv, loss_var, loss_cov\n",
    "\n",
    "\n",
    "class VICRegModel(tf.keras.Model):\n",
    "    def __init__(self, encoder, projection_head, c_inv=25, c_var=25, c_cov=1, **kwargs):\n",
    "        super(VICRegModel, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.projection_head = projection_head\n",
    "        self.c_inv = c_inv\n",
    "        self.c_var = c_var\n",
    "        self.c_cov = c_cov\n",
    "\n",
    "    def compile(self, optimizer, **kwargs):\n",
    "        super(VICRegModel, self).compile(**kwargs)\n",
    "        self.optimizer = optimizer\n",
    "\n",
    "    def train_step(self, data):\n",
    "        # view1, view2\n",
    "        x1, x2 = data\n",
    "        with tf.GradientTape() as tape:\n",
    "            emb1 = self.encoder(x1, training=True)\n",
    "            emb2 = self.encoder(x2, training=True)\n",
    "\n",
    "            z1 = self.projection_head(emb1, training=True)\n",
    "            z2 = self.projection_head(emb2, training=True)\n",
    "\n",
    "            loss, loss_inv, loss_var, loss_cov = vicreg_loss(z1, z2,\n",
    "                                                             c_inv=self.c_inv,\n",
    "                                                             c_var=self.c_var,\n",
    "                                                             c_cov=self.c_cov)\n",
    "        \n",
    "        vars = self.encoder.trainable_variables + self.projection_head.trainable_variables\n",
    "        grads = tape.gradient(loss, vars)\n",
    "        self.optimizer.apply_gradients(zip(grads, vars))\n",
    "\n",
    "        return {\"loss\": loss, \"loss_inv\": loss_inv, \"loss_var\": loss_var, \"loss_cov\": loss_cov}\n",
    "\n",
    "\n",
    "def build_classifier(encoder):\n",
    "    # update the encoder weights?\n",
    "    encoder.trainable = False\n",
    "\n",
    "    inputs = tf.keras.Input(shape=(64, 50, 6))\n",
    "    # option training here concerns about computations in dropout, batchnorm etc. \n",
    "    x = encoder(inputs, training=False)\n",
    "    x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
    "    outputs = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    return tf.keras.Model(inputs, outputs, name=\"classifier\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b64ba85",
   "metadata": {},
   "source": [
    "## train vicreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772c811d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "pu_min = 100\n",
    "pu_max = 200\n",
    "\n",
    "gen_data_contrastive = generate_batch_for_contrastive(X_hs=X_HHbbbb_isHS,\n",
    "                                                      X_pu=X_HHbbbb_isPU,\n",
    "                                                      X_bkg=X_PJZ0,\n",
    "                                                      pu_min=pu_min,\n",
    "                                                      pu_max=pu_max,\n",
    "                                                      batch_size=batch_size)\n",
    "\n",
    "encoder = build_encoder(input_shape=(64, 50, 6), embedding_dim=128)\n",
    "projection_head = build_projection_head(embedding_dim=128, projection_dim=64)\n",
    "\n",
    "vicreg_model = VICRegModel(encoder=encoder, projection_head=projection_head, c_inv=25, c_var=25, c_cov=1)\n",
    "vicreg_model.compile(optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001))\n",
    "\n",
    "vicreg_model.fit(gen_data_contrastive, steps_per_epoch=30, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620f9028",
   "metadata": {},
   "source": [
    "## train classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7389b5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_data_classification = generate_batch_for_classifier(X_hs=X_HHbbbb_isHS,\n",
    "                                                        X_pu=X_HHbbbb_isPU,\n",
    "                                                        X_bkg=X_PJZ0,\n",
    "                                                        pu_min=pu_min,\n",
    "                                                        pu_max=pu_max,\n",
    "                                                        batch_size=batch_size)\n",
    "\n",
    "classifier = build_classifier(encoder, embedding_dim=128)\n",
    "classifier.compile(optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "                   loss='binary_crossentropy',\n",
    "                   metrics=['accuracy'])\n",
    "\n",
    "classifier.fit(gen_data_classification, steps_per_epoch=30, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f13baed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "contrastive",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
